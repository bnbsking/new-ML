{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers.convolutional import Convolution2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from functools import partial\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64               # 64\n",
    "TRAINING_RATIO = 5            # discriminator updates per generator update\n",
    "GRADIENT_PENALTY_WEIGHT = 10  # As per the paper\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples, gradient_penalty_weight):\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
    "    return K.mean(gradient_penalty)\n",
    "\n",
    "def make_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=100))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(128 * 7 * 7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128 * 7 * 7,)))\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Convolution2D(64, (5, 5), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Convolution2D(1, (5, 5), padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    "def make_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, (5, 5), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Convolution2D(128, (5, 5), kernel_initializer='he_normal', strides=[2, 2]))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Convolution2D(128, (5, 5), kernel_initializer='he_normal', padding='same', \\\n",
    "        strides=[2, 2]))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(1, kernel_initializer='he_normal'))\n",
    "    return model\n",
    "\n",
    "def tile_images(image_stack):\n",
    "    assert len(image_stack.shape) == 3\n",
    "    image_list = [image_stack[i, :, :] for i in range(image_stack.shape[0])]\n",
    "    tiled_images = np.concatenate(image_list, axis=1)\n",
    "    return tiled_images\n",
    "\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    def _merge_function(self, inputs):\n",
    "        weights = K.random_uniform((BATCH_SIZE, 1, 1, 1))\n",
    "        return (weights * inputs[0]) + ((1 - weights) * inputs[1])\n",
    "\n",
    "def generate_images(generator_model, epoch):\n",
    "    test_image_stack = generator_model.predict(np.random.rand(10, 100))\n",
    "    test_image_stack = (test_image_stack * 127.5) + 127.5\n",
    "    test_image_stack = np.squeeze(np.round(test_image_stack).astype(np.uint8))\n",
    "    tiled_output = tile_images(test_image_stack)\n",
    "    tiled_output = Image.fromarray(tiled_output, mode='L')  # L specifies greyscale\n",
    "    tiled_output.save('epoch_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "X_train = (X_train.reshape((60000, 28, 28, 1)) - 127.5) / 127.5\n",
    "\n",
    "generator, discriminator = make_generator(), make_discriminator()\n",
    "\n",
    "for layer in discriminator.layers:\n",
    "    layer.trainable = False\n",
    "discriminator.trainable = False\n",
    "generator_input = Input(shape=(100,))\n",
    "generator_layers = generator(generator_input)\n",
    "discriminator_layers_for_generator = discriminator(generator_layers)\n",
    "generator_model = Model(inputs=[generator_input], outputs=[discriminator_layers_for_generator])\n",
    "generator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss=wasserstein_loss)\n",
    "\n",
    "for layer in discriminator.layers:\n",
    "    layer.trainable = True\n",
    "for layer in generator.layers:\n",
    "    layer.trainable = False\n",
    "discriminator.trainable = True\n",
    "generator.trainable = False\n",
    "real_samples = Input(shape=(28,28,1))\n",
    "generator_input_for_discriminator = Input(shape=(100,))\n",
    "generated_samples_for_discriminator = generator(generator_input_for_discriminator)\n",
    "discriminator_output_from_generator = discriminator(generated_samples_for_discriminator)\n",
    "discriminator_output_from_real_samples = discriminator(real_samples)\n",
    "\n",
    "averaged_samples = RandomWeightedAverage()([real_samples, generated_samples_for_discriminator])\n",
    "averaged_samples_out = discriminator(averaged_samples)\n",
    "partial_gp_loss = partial(gradient_penalty_loss, averaged_samples=averaged_samples, \\\n",
    "    gradient_penalty_weight=GRADIENT_PENALTY_WEIGHT)\n",
    "partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "\n",
    "discriminator_model = Model(inputs=[real_samples, generator_input_for_discriminator], \\\n",
    "    outputs=[discriminator_output_from_real_samples, discriminator_output_from_generator, \\\n",
    "    averaged_samples_out])\n",
    "discriminator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss=\\\n",
    "    [wasserstein_loss, wasserstein_loss, partial_gp_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "WARNING:tensorflow:From c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "c:\\users\\james\\miniconda3\\envs\\tf1\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "negative_y = -positive_y\n",
    "dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    np.random.shuffle(X_train)\n",
    "    discriminator_loss, generator_loss = [], []\n",
    "    minibatches_size = BATCH_SIZE * TRAINING_RATIO\n",
    "    for i in range(int(X_train.shape[0]/minibatches_size)):\n",
    "        discriminator_minibatches = X_train[i * minibatches_size: (i + 1) * minibatches_size]\n",
    "        for j in range(TRAINING_RATIO):\n",
    "            image_batch = discriminator_minibatches[j * BATCH_SIZE: (j + 1) * BATCH_SIZE]\n",
    "            noise = np.random.rand(BATCH_SIZE, 100).astype(np.float32)\n",
    "            discriminator_loss.append(discriminator_model.train_on_batch( [image_batch, noise],\\\n",
    "                [positive_y, negative_y, dummy_y]))\n",
    "        generator_loss.append(generator_model.train_on_batch(np.random.rand(BATCH_SIZE,100), \\\n",
    "            positive_y))\n",
    "    generate_images(generator, epoch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(discriminator_loss))\n",
    "discriminator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(generator_loss))\n",
    "generator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
