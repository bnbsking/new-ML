{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "affected-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784) (1000,) (1000, 784) (1000,) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# pip install netron # netron <model>\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "(xTrain, yTrain), (xVal, yVal) = tf.keras.datasets.mnist.load_data()\n",
    "xTrain, yTrain = xTrain[:1000].reshape(-1,784)/255., yTrain[:1000]\n",
    "xVal, yVal = xVal[:1000].reshape(-1,784)/255., yVal[:1000]\n",
    "noise = np.random.random((1000,1))\n",
    "print(xTrain.shape, yTrain.shape, xVal.shape, yVal.shape, noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "expected-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 64)           50240       input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 4)            8           input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 10)           650         dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 4)            20          dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 14)           0           dense_77[0][0]                   \n",
      "                                                                 dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 64)           960         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 1)            65          dense_80[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 51,943\n",
      "Trainable params: 51,943\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# multiple inputs\n",
    "inputA = Input(shape=(784,))\n",
    "x = Dense(64, activation='relu')(inputA)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "\n",
    "inputB = Input(shape=(1,))\n",
    "y = Dense(4, activation='relu')(inputB)\n",
    "y = Dense(4, activation='relu')(y)\n",
    "\n",
    "z = concatenate([x,y])\n",
    "z = Dense(64, activation=\"relu\")(z)\n",
    "z = Dense(1)(z)\n",
    "model = Model(inputs=[inputA, inputB], outputs=z)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ahead-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 27.4082 - val_loss: 23.8064\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 22.3682 - val_loss: 16.4101\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 14.0333 - val_loss: 8.7280\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 10.0483 - val_loss: 7.9225\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8.3838 - val_loss: 6.3691\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.5621 - val_loss: 5.2282\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.1062 - val_loss: 4.7771\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.3999 - val_loss: 4.6419\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.0607 - val_loss: 4.5886\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.7811 - val_loss: 4.4503\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.5138 - val_loss: 4.2585\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.2622 - val_loss: 4.0944\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0586 - val_loss: 3.9541\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.8521 - val_loss: 3.8764\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.6622 - val_loss: 3.7770\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.5191 - val_loss: 3.6728\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3655 - val_loss: 3.6443\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.1995 - val_loss: 3.5228\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.0596 - val_loss: 3.4102\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.9383 - val_loss: 3.4630\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.8067 - val_loss: 3.2447\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6858 - val_loss: 3.1721\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.5769 - val_loss: 3.1507\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.4356 - val_loss: 3.1171\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3221 - val_loss: 3.0375\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.2248 - val_loss: 2.9744\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1298 - val_loss: 2.9778\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0500 - val_loss: 2.9718\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9589 - val_loss: 2.8755\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8597 - val_loss: 2.8653\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8122 - val_loss: 2.8718\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7491 - val_loss: 2.8926\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7014 - val_loss: 2.8669\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6433 - val_loss: 2.9543\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5666 - val_loss: 2.7695\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5125 - val_loss: 2.7370\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4523 - val_loss: 2.7389\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4250 - val_loss: 2.6641\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3759 - val_loss: 2.7164\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3415 - val_loss: 2.7129\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3253 - val_loss: 2.6657\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3003 - val_loss: 2.6285\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2622 - val_loss: 2.5982\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([xTrain,noise], yTrain, validation_data=([xVal,noise], yVal), epochs=100, \n",
    "    batch_size=128, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3,\n",
    "    min_delta=0.1, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adopted-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2541447]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([xTrain[0].reshape(1,-1), np.random.random((1,1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "laden-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"forkInput.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-snapshot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "vocational-merchandise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 64)           50240       input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 10)           650         dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 1)            65          dense_50[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 50,955\n",
      "Trainable params: 50,955\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# multiple outputs\n",
    "inputL = Input(shape=(784,))\n",
    "x = Dense(64, activation='relu')(inputL)\n",
    "y = Dense(10, activation='relu')(x)\n",
    "z = Dense(1)(x)\n",
    "model = Model(inputs=inputL, outputs=[y,z])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=['mse','mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "impaired-comedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 24.5572 - dense_51_loss: 24.2419 - dense_52_loss: 0.3154 - val_loss: 19.6488 - val_dense_51_loss: 19.4374 - val_dense_52_loss: 0.2114\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 18.3844 - dense_51_loss: 18.2198 - dense_52_loss: 0.1647 - val_loss: 14.4070 - val_dense_51_loss: 14.2196 - val_dense_52_loss: 0.1874\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.0296 - dense_51_loss: 13.8835 - dense_52_loss: 0.1461 - val_loss: 10.5956 - val_dense_51_loss: 10.4321 - val_dense_52_loss: 0.1635\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 10.5292 - dense_51_loss: 10.3955 - dense_52_loss: 0.1337 - val_loss: 7.9306 - val_dense_51_loss: 7.7683 - val_dense_52_loss: 0.1623\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.3359 - dense_51_loss: 8.2084 - dense_52_loss: 0.1275 - val_loss: 6.7043 - val_dense_51_loss: 6.5565 - val_dense_52_loss: 0.1478\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.1183 - dense_51_loss: 7.0010 - dense_52_loss: 0.1173 - val_loss: 6.0710 - val_dense_51_loss: 5.9344 - val_dense_52_loss: 0.1366\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.2348 - dense_51_loss: 6.1273 - dense_52_loss: 0.1075 - val_loss: 5.5415 - val_dense_51_loss: 5.4098 - val_dense_52_loss: 0.1317\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.4960 - dense_51_loss: 5.3934 - dense_52_loss: 0.1026 - val_loss: 5.1864 - val_dense_51_loss: 5.0629 - val_dense_52_loss: 0.1235\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.0093 - dense_51_loss: 4.9111 - dense_52_loss: 0.0982 - val_loss: 5.0035 - val_dense_51_loss: 4.8841 - val_dense_52_loss: 0.1193\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.6769 - dense_51_loss: 4.5830 - dense_52_loss: 0.0938 - val_loss: 4.8854 - val_dense_51_loss: 4.7680 - val_dense_52_loss: 0.1174\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.4308 - dense_51_loss: 4.3395 - dense_52_loss: 0.0913 - val_loss: 4.7985 - val_dense_51_loss: 4.6818 - val_dense_52_loss: 0.1167\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.2465 - dense_51_loss: 4.1578 - dense_52_loss: 0.0886 - val_loss: 4.7093 - val_dense_51_loss: 4.5929 - val_dense_52_loss: 0.1164\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.1197 - dense_51_loss: 4.0326 - dense_52_loss: 0.0871 - val_loss: 4.6578 - val_dense_51_loss: 4.5414 - val_dense_52_loss: 0.1165\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.9252 - dense_51_loss: 3.8400 - dense_52_loss: 0.0851 - val_loss: 4.5504 - val_dense_51_loss: 4.4346 - val_dense_52_loss: 0.1159\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.8224 - dense_51_loss: 3.7375 - dense_52_loss: 0.0849 - val_loss: 4.5024 - val_dense_51_loss: 4.3842 - val_dense_52_loss: 0.1183\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.6841 - dense_51_loss: 3.6009 - dense_52_loss: 0.0832 - val_loss: 4.4548 - val_dense_51_loss: 4.3399 - val_dense_52_loss: 0.1149\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.5691 - dense_51_loss: 3.4881 - dense_52_loss: 0.0810 - val_loss: 4.3860 - val_dense_51_loss: 4.2711 - val_dense_52_loss: 0.1150\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4656 - dense_51_loss: 3.3859 - dense_52_loss: 0.0796 - val_loss: 4.3168 - val_dense_51_loss: 4.2034 - val_dense_52_loss: 0.1134\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3643 - dense_51_loss: 3.2873 - dense_52_loss: 0.0770 - val_loss: 4.2744 - val_dense_51_loss: 4.1614 - val_dense_52_loss: 0.1130\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.2698 - dense_51_loss: 3.1941 - dense_52_loss: 0.0757 - val_loss: 4.2586 - val_dense_51_loss: 4.1437 - val_dense_52_loss: 0.1149\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.1938 - dense_51_loss: 3.1186 - dense_52_loss: 0.0752 - val_loss: 4.1940 - val_dense_51_loss: 4.0803 - val_dense_52_loss: 0.1137\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.1021 - dense_51_loss: 3.0284 - dense_52_loss: 0.0737 - val_loss: 4.1883 - val_dense_51_loss: 4.0742 - val_dense_52_loss: 0.1141\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.0299 - dense_51_loss: 2.9571 - dense_52_loss: 0.0728 - val_loss: 4.1188 - val_dense_51_loss: 4.0049 - val_dense_52_loss: 0.1139\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.9672 - dense_51_loss: 2.8956 - dense_52_loss: 0.0715 - val_loss: 4.0858 - val_dense_51_loss: 3.9730 - val_dense_52_loss: 0.1128\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.8808 - dense_51_loss: 2.8098 - dense_52_loss: 0.0710 - val_loss: 4.0631 - val_dense_51_loss: 3.9498 - val_dense_52_loss: 0.1133\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.8196 - dense_51_loss: 2.7488 - dense_52_loss: 0.0707 - val_loss: 4.0348 - val_dense_51_loss: 3.9207 - val_dense_52_loss: 0.1140\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.7603 - dense_51_loss: 2.6895 - dense_52_loss: 0.0708 - val_loss: 3.9968 - val_dense_51_loss: 3.8833 - val_dense_52_loss: 0.1135\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.7143 - dense_51_loss: 2.6429 - dense_52_loss: 0.0713 - val_loss: 3.9556 - val_dense_51_loss: 3.8405 - val_dense_52_loss: 0.1151\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6345 - dense_51_loss: 2.5658 - dense_52_loss: 0.0686 - val_loss: 3.9593 - val_dense_51_loss: 3.8451 - val_dense_52_loss: 0.1143\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.5906 - dense_51_loss: 2.5227 - dense_52_loss: 0.0678 - val_loss: 3.8904 - val_dense_51_loss: 3.7769 - val_dense_52_loss: 0.1134\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.5423 - dense_51_loss: 2.4750 - dense_52_loss: 0.0673 - val_loss: 3.8828 - val_dense_51_loss: 3.7696 - val_dense_52_loss: 0.1132\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.4950 - dense_51_loss: 2.4278 - dense_52_loss: 0.0672 - val_loss: 3.8714 - val_dense_51_loss: 3.7561 - val_dense_52_loss: 0.1153\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.4296 - dense_51_loss: 2.3631 - dense_52_loss: 0.0665 - val_loss: 3.8289 - val_dense_51_loss: 3.7153 - val_dense_52_loss: 0.1135\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.3851 - dense_51_loss: 2.3186 - dense_52_loss: 0.0665 - val_loss: 3.8337 - val_dense_51_loss: 3.7206 - val_dense_52_loss: 0.1130\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.3433 - dense_51_loss: 2.2780 - dense_52_loss: 0.0653 - val_loss: 3.7778 - val_dense_51_loss: 3.6626 - val_dense_52_loss: 0.1151\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.2978 - dense_51_loss: 2.2312 - dense_52_loss: 0.0667 - val_loss: 3.7466 - val_dense_51_loss: 3.6309 - val_dense_52_loss: 0.1158\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.2489 - dense_51_loss: 2.1814 - dense_52_loss: 0.0675 - val_loss: 3.7618 - val_dense_51_loss: 3.6447 - val_dense_52_loss: 0.1171\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.2070 - dense_51_loss: 2.1380 - dense_52_loss: 0.0689 - val_loss: 3.7051 - val_dense_51_loss: 3.5912 - val_dense_52_loss: 0.1139\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.1512 - dense_51_loss: 2.0859 - dense_52_loss: 0.0653 - val_loss: 3.7288 - val_dense_51_loss: 3.6127 - val_dense_52_loss: 0.1161\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.1248 - dense_51_loss: 2.0602 - dense_52_loss: 0.0646 - val_loss: 3.6721 - val_dense_51_loss: 3.5592 - val_dense_52_loss: 0.1129\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 2.0691 - dense_51_loss: 2.0053 - dense_52_loss: 0.0638 - val_loss: 3.6842 - val_dense_51_loss: 3.5659 - val_dense_52_loss: 0.1183\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.0289 - dense_51_loss: 1.9641 - dense_52_loss: 0.0648 - val_loss: 3.6326 - val_dense_51_loss: 3.5168 - val_dense_52_loss: 0.1158\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.0004 - dense_51_loss: 1.9377 - dense_52_loss: 0.0626 - val_loss: 3.6139 - val_dense_51_loss: 3.4991 - val_dense_52_loss: 0.1148\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.9475 - dense_51_loss: 1.8841 - dense_52_loss: 0.0634 - val_loss: 3.6009 - val_dense_51_loss: 3.4850 - val_dense_52_loss: 0.1158\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8958 - dense_51_loss: 1.8332 - dense_52_loss: 0.0626 - val_loss: 3.5975 - val_dense_51_loss: 3.4826 - val_dense_52_loss: 0.1150\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.8566 - dense_51_loss: 1.7950 - dense_52_loss: 0.0617 - val_loss: 3.5693 - val_dense_51_loss: 3.4546 - val_dense_52_loss: 0.1147\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8249 - dense_51_loss: 1.7638 - dense_52_loss: 0.0611 - val_loss: 3.5428 - val_dense_51_loss: 3.4245 - val_dense_52_loss: 0.1183\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7910 - dense_51_loss: 1.7276 - dense_52_loss: 0.0635 - val_loss: 3.5228 - val_dense_51_loss: 3.4064 - val_dense_52_loss: 0.1164\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7407 - dense_51_loss: 1.6792 - dense_52_loss: 0.0614 - val_loss: 3.5075 - val_dense_51_loss: 3.3902 - val_dense_52_loss: 0.1173\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.6972 - dense_51_loss: 1.6370 - dense_52_loss: 0.0602 - val_loss: 3.4871 - val_dense_51_loss: 3.3719 - val_dense_52_loss: 0.1152\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6633 - dense_51_loss: 1.6044 - dense_52_loss: 0.0589 - val_loss: 3.4695 - val_dense_51_loss: 3.3536 - val_dense_52_loss: 0.1159\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6275 - dense_51_loss: 1.5685 - dense_52_loss: 0.0590 - val_loss: 3.4622 - val_dense_51_loss: 3.3462 - val_dense_52_loss: 0.1160\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.5951 - dense_51_loss: 1.5361 - dense_52_loss: 0.0590 - val_loss: 3.4482 - val_dense_51_loss: 3.3314 - val_dense_52_loss: 0.1168\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.5522 - dense_51_loss: 1.4940 - dense_52_loss: 0.0582 - val_loss: 3.4258 - val_dense_51_loss: 3.3095 - val_dense_52_loss: 0.1163\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.5228 - dense_51_loss: 1.4647 - dense_52_loss: 0.0581 - val_loss: 3.4206 - val_dense_51_loss: 3.3039 - val_dense_52_loss: 0.1168\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.4853 - dense_51_loss: 1.4264 - dense_52_loss: 0.0590 - val_loss: 3.3896 - val_dense_51_loss: 3.2730 - val_dense_52_loss: 0.1167\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.4479 - dense_51_loss: 1.3899 - dense_52_loss: 0.0580 - val_loss: 3.3892 - val_dense_51_loss: 3.2725 - val_dense_52_loss: 0.1167\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.4166 - dense_51_loss: 1.3588 - dense_52_loss: 0.0578 - val_loss: 3.3669 - val_dense_51_loss: 3.2481 - val_dense_52_loss: 0.1188\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3786 - dense_51_loss: 1.3208 - dense_52_loss: 0.0578 - val_loss: 3.3453 - val_dense_51_loss: 3.2254 - val_dense_52_loss: 0.1199\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3483 - dense_51_loss: 1.2906 - dense_52_loss: 0.0577 - val_loss: 3.3166 - val_dense_51_loss: 3.1994 - val_dense_52_loss: 0.1173\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xTrain, [yTrain,noise], validation_data=(xVal, [yVal,noise]), epochs=100, \n",
    "    batch_size=128, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3,\n",
    "    min_delta=0.1, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "simple-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.585515 , 4.666171 , 4.5040517, 4.271038 , 4.3687186, 4.5968385,\n",
       "         4.584263 , 4.5527825, 4.1127515, 4.5533705]], dtype=float32),\n",
       " array([[0.49326444]], dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(xTrain[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "interesting-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"forkOutput.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-lotus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "stock-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 64)           50240       input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 64)           50240       input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 128)          0           dense_82[0][0]                   \n",
      "                                                                 dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 10)           1290        concatenate_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# multiple hidden\n",
    "inputL = Input(shape=(784,))\n",
    "x = Dense(64)(inputL)\n",
    "y = Dense(64)(inputL)\n",
    "z = concatenate([x,y])\n",
    "z = Dense(10)(z)\n",
    "model = Model(inputL, z)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "elder-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 18.4460 - val_loss: 9.3522\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 10.2493 - val_loss: 8.0864\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.8836 - val_loss: 6.0717\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.0142 - val_loss: 5.4015\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.0649 - val_loss: 5.0186\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.5858 - val_loss: 4.9899\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.3525 - val_loss: 4.8260\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.1366 - val_loss: 4.7360\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.9643 - val_loss: 4.5664\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.7923 - val_loss: 4.4673\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.6642 - val_loss: 4.4221\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.5449 - val_loss: 4.3637\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4363 - val_loss: 4.3315\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3552 - val_loss: 4.2823\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.2661 - val_loss: 4.2603\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.1872 - val_loss: 4.2387\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.1555 - val_loss: 4.2019\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.1018 - val_loss: 4.1557\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.0460 - val_loss: 4.1905\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.9667 - val_loss: 4.1555\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.9182 - val_loss: 4.1305\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.8937 - val_loss: 4.1245\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.8623 - val_loss: 4.1256\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.8042 - val_loss: 4.0716\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.7738 - val_loss: 4.0868\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.7492 - val_loss: 4.0903\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.7125 - val_loss: 4.1293\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xTrain, yTrain, validation_data=(xVal, yVal), epochs=100, \n",
    "    batch_size=128, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3,\n",
    "    min_delta=0.1, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "regulated-navigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.290557 , 4.0267296, 4.236226 , 4.2261214, 4.3456116, 4.0416994,\n",
       "        4.236514 , 4.0841002, 4.151796 , 4.3222246]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(xTrain[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "square-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"forkHidden.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-injury",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
